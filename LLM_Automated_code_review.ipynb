{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "id": "SuX9NrFVbSXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = 'sk-###########' #add openai api key here\n",
        "\n",
        "def evaluate_code_with_llm(code):\n",
        "    try:\n",
        "        # Prompt to clarify the intent of the code\n",
        "        prompt = f\"What does the following Python code do?\\n\\n{code}\\n\\nAnswer:\"\n",
        "\n",
        "        # Use the completion API to get the model's answer\n",
        "        response = openai.Completion.create(\n",
        "            engine=\"davinci-002\",\n",
        "            prompt=prompt,\n",
        "            max_tokens=100\n",
        "        )\n",
        "\n",
        "        return response.choices[0].text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error occurred: {str(e)}\"\n",
        "\n",
        "def grant_points(code, correct_answer):\n",
        "    # Here, you can implement your logic to grant points based on correctness\n",
        "    # For simplicity, let's say if the LLM's response matches the correct answer, grant 1 point\n",
        "    if code == correct_answer:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def main():\n",
        "    # User-provided coding question\n",
        "    question = input(\"Enter your coding question: \")\n",
        "\n",
        "    # User-provided Python code\n",
        "    code = input(\"Enter your Python code: \")\n",
        "\n",
        "    # Correct answer for the given code (You might want to have a database or predefined answers)\n",
        "    correct_answer = \"The code performs the desired operation correctly.\"\n",
        "\n",
        "    # Use LLM to evaluate the code\n",
        "    evaluation_result = evaluate_code_with_llm(code)\n",
        "    print(f\"LLM's Evaluation: {evaluation_result}\")\n",
        "\n",
        "    # Grant points based on code correctness\n",
        "    points = grant_points(evaluation_result, correct_answer)\n",
        "    print(f\"Points Granted: {points}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "qp4EzjVnZhZY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}